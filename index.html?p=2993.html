<!DOCTYPE html>
<!--[if IE 6]>
<html id="ie6" lang="en-US">
<![endif]-->
<!--[if IE 7]>
<html id="ie7" lang="en-US">
<![endif]-->
<!--[if IE 8]>
<html id="ie8" lang="en-US">
<![endif]-->
<!--[if !(IE 6) & !(IE 7) & !(IE 8)]><!-->
<html lang="en-US">
<!--<![endif]-->
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width" />
<title>
Problems with WikiLeaks and the Start of a Solution | Future of News and Participatory Media	</title>
<link rel="profile" href="http://gmpg.org/xfn/11" />
<link rel="stylesheet" type="text/css" media="all" href="wp-content/themes/twentyeleven/style.css" />
<link rel="pingback" href="https://partnews.mit.edu/xmlrpc.php">
<!--[if lt IE 9]>
<script src="https://partnews.mit.edu/wp-content/themes/twentyeleven/js/html5.js" type="text/javascript"></script>
<![endif]-->
<link rel='dns-prefetch' href='https://s.w.org/' />
<link rel="alternate" type="application/rss+xml" title="Future of News and Participatory Media &raquo; Feed" href="feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="Future of News and Participatory Media &raquo; Comments Feed" href="comments/feed/index.html" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/partnews.mit.edu\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.2"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='wp-includes/css/dist/block-library/style.min.css%3Fver=5.2.css' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-theme-css'  href='wp-includes/css/dist/block-library/theme.min.css%3Fver=5.2.css' type='text/css' media='all' />
<link rel='stylesheet' id='twentyeleven-block-style-css'  href='wp-content/themes/twentyeleven/blocks.css%3Fver=20181230.css' type='text/css' media='all' />
<script type='text/javascript' src='wp-includes/js/jquery/jquery.js%3Fver=1.12.4'></script>
<script type='text/javascript' src='wp-includes/js/jquery/jquery-migrate.min.js%3Fver=1.4.1'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var MyAjax = {"ajaxurl":"https:\/\/partnews.mit.edu\/wp-admin\/admin-ajax.php","security":"163cab58e4"};
/* ]]> */
</script>
<script type='text/javascript' src='wp-content/plugins/advanced-iframe/js/ai.js%3Fver=834912'></script>
<link rel='https://api.w.org/' href='wp-json/index.html' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="xmlrpc.php%3Frsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='Validate a Social Media Movement' href='index.html%3Fp=2984.html' />
<link rel='next' title='my news spaces' href='index.html%3Fp=3171.html' />
<meta name="generator" content="WordPress 5.2" />
<link rel="canonical" href="index.html%3Fp=2993.html" />
<link rel='shortlink' href='index.html%3Fp=2993.html' />
<link rel="alternate" type="application/json+oembed" href="wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fpartnews.mit.edu%252F2013%252F05%252F30%252Fproblems-with-wikileaks-and-the-start-of-a-solution%252F" />
<link rel="alternate" type="text/xml+oembed" href="wp-json/oembed/1.0/embed%3Furl=https:%252F%252Fpartnews.mit.edu%252F2013%252F05%252F30%252Fproblems-with-wikileaks-and-the-start-of-a-solution%252F&amp;format=xml" />
		<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
				<style type="text/css" id="twentyeleven-header-css">
				#site-title,
		#site-description {
			position: absolute;
			clip: rect(1px 1px 1px 1px); /* IE6, IE7 */
			clip: rect(1px, 1px, 1px, 1px);
		}
				</style>
		<style type="text/css" id="custom-background-css">
body.custom-background { background-image: url("https://partnews.brownbag.me/wp-content/uploads/2014/02/poster.jpg"); background-position: left top; background-size: auto; background-repeat: repeat; background-attachment: fixed; }
</style>
	</head>

<body class="post-template-default single single-post postid-2993 single-format-standard custom-background wp-embed-responsive singular two-column right-sidebar">
<div id="page" class="hfeed">
	<header id="branding" role="banner">
			<hgroup>
				<h1 id="site-title"><span><a href="index.html" rel="home">Future of News and Participatory Media</a></span></h1>
				<h2 id="site-description">Treating newsgathering as an engineering problem&#8230; since 2012!</h2>
			</hgroup>

						<a href="index.html">
									<img src="https://partnews.brownbag.me/wp-content/uploads/2014/02/header2.gif" width="1000" height="288" alt="Future of News and Participatory Media" />
							</a>
			
						<div class="only-search with-image">
					<form method="get" id="searchform" action="index.html">
		<label for="s" class="assistive-text">Search</label>
		<input type="text" class="field" name="s" id="s" placeholder="Search" />
		<input type="submit" class="submit" name="submit" id="searchsubmit" value="Search" />
	</form>
			</div>
				
			<nav id="access" role="navigation">
				<h3 class="assistive-text">Main menu</h3>
								<div class="skip-link"><a class="assistive-text" href="index.html%3Fp=2993.html#content">Skip to primary content</a></div>
												<div class="menu-main-menu-container"><ul id="menu-main-menu" class="menu"><li id="menu-item-5119" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-5119"><a href="http://partnews.brownbag.me/">Home</a></li>
<li id="menu-item-160" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-160"><a href="index.html%3Fp=16.html">Syllabus</a></li>
<li id="menu-item-3899" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3899"><a href="index.html%3Fp=1991.html">Resources</a></li>
<li id="menu-item-10131" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-10131"><a href="index.html%3Fp=10109.html">2019 Class Bios</a></li>
<li id="menu-item-5114" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-5114"><a href="index.html%3Fp=5112.html">Assignments</a></li>
</ul></div>			</nav><!-- #access -->
	</header><!-- #branding -->


	<div id="main">

		<div id="primary">
			<div id="content" role="main">

				
					<nav id="nav-single">
						<h3 class="assistive-text">Post navigation</h3>
						<span class="nav-previous"><a href="index.html%3Fp=2984.html" rel="prev"><span class="meta-nav">&larr;</span> Previous</a></span>
						<span class="nav-next"><a href="index.html%3Fp=3171.html" rel="next">Next <span class="meta-nav">&rarr;</span></a></span>
					</nav><!-- #nav-single -->

					
<article id="post-2993" class="post-2993 post type-post status-publish format-standard hentry category-all category-final-projects">
	<header class="entry-header">
		<h1 class="entry-title">Problems with WikiLeaks and the Start of a Solution</h1>

				<div class="entry-meta">
			<span class="sep">Posted on </span><a href="index.html%3Fp=2993.html" title="9:27 pm" rel="bookmark"><time class="entry-date" datetime="2013-05-30T21:27:23-05:00">May 30, 2013</time></a><span class="by-author"> <span class="sep"> by </span> <span class="author vcard"><a class="url fn n" href="author/mc/index.html" title="View all posts by MC" rel="author">MC</a></span></span>		</div><!-- .entry-meta -->
			</header><!-- .entry-header -->

	<div class="entry-content">
		<p><a href="http://wikileaks.org">WikiLeaks</a> has been an important step toward greater transparency and accountability. By publishing leaked documents from governments, corporations and other institutions, WikiLeaks has revealed the power of transparency and openness online. That said, WikiLeaks has some serious flaws with their own transparency, openness of their releases, and methods.</p>
<p>This is an exploration of some of the problems with WikiLeaks through a story of my attempt to analyze the WikiLeaks <a href="http://wikileaks.org/the-gifiles.html">Global Intelligence Files release</a>. The Global Intelligence Files (GI Files) are a collection of five million emails from the intelligence contractor <a href="https://www.stratfor.com/%E2%80%9D">Stratfor</a>. These emails are from the years 2004 to 2011 and discuss Stratfor’s internal operations.</p>
<p>I was hoping to analyze Stratfor’s <a href="http://estaticos.elmundo.es/documentos/2010/12/01/conspiracies.pdf">communication structures</a> by making a network graph from the GI Files. Email is perfect for this sort of analysis. Someone made a tool called <a href="https://github.com/wlwardiary/cable2graph">cable2graph</a> for graph analysis of <a href="http://www.wikileaks.ch/cablegate.html">Cablegate</a>, so I planned to adapt that tool for use with emails. </p>
<p>Ideally, I would use all the Stratfor emails for this graph analysis. Unfortunately, WikiLeaks has not released all the Global Intelligence Files yet. They started publishing the GI Files on <a href="http://www.youtube.com/watch?v=T8NII5v9keY">February 27th, 2012</a>. This was over a year ago. Five million documents is a lot, but after fifteen months only a fraction of the documents have been released. It does not seem like WikiLeaks is seriously trying to release these documents. They have not released any sets of emails since <a href="http://wikileaks.org/gifiles/releasedate/2013-02-17-00-alpha-more-insight-yemen-awlaki-death-op-sa701.html">February 2013</a> and most months only several sets of emails are published. Even considering time spent reviewing documents before release, the release of the GI Files is taking far too long. </p>
<p>The second issue with analyzing the Global Intelligence Files is WikiLeaks’s release strategy. WikiLeaks is working with <a href="https://wikileaks.org/the-gifiles.html%E2%80%9D">“more than 25 media partners”</a> to release the documents. These partners get access to the full set of documents. WikiLeaks releases GI Files emails only when a partner writes an article about them. WikiLeaks has released a few hundred sets of these emails so far, but most of these releases only contain a few documents.</p>
<p>This release strategy makes it incredibly difficult to find new stories in released Stratfor emails. After all, the emails are only released when they have been used in a story already. This means there is no obvious way for most WikiLeaks supporters to help with the release and analysis of the GI Files. Partners are <a href="http://cryptome.org/2012/06/wikileaks-trap.htm">invited</a> and must be “﻿a journalist, Professor or Associate Professor at a University or an employee of a human rights organisation.” In some ways, this is worse than a pay wall. Access to the GI Files is restricted and there is no clear way someone can get access.</p>
<p>Despite these difficulties, I thought using network graphs to examine the bigger picture of all the released emails may still reveal some new information. WikiLeaks does very little analysis of most of its documents. For the GI Files, WikiLeaks seems to rely entirely on the analyses done by their media partners. Unfortunately, WikiLeaks makes it difficult to analyze most of their releases. A few, like Cablegate, are accessible in machine readable formats. People have used these formats to <a href="http://www.cabledrum.net/news/redactions">analyze</a> <a href="http://www.cablegatesearch.net/">the</a> <a href="https://github.com/elishowk/cablegate_semnet">documents</a> <a href="http://aebr.home.xs4all.nl/wl/">in</a> <a href="https://github.com/wlwardiary/cable2graph">interesting</a> <a href="https://www.aftenposten.no/spesial/cablegate/?lang=en">ways</a>.</p>
<p>Most WikiLeaks releases are not accessible in machine readable formats. There are no machine readable versions of the Global Intelligence Files. As of this month, the US government has <a href="http://www.whitehouse.gov/the-press-office/2013/05/09/executive-order-making-open-and-machine-readable-new-default-government-">better policies for releasing machine readable data than WikiLeaks</a>. This new policy is a great step forward for the US government, but it is a huge failure for WikiLeaks that they are now behind the US government on certain transparency policies.</p>
<p>To get the GI Files email data in machine readable format, I wrote a <a href="https://scraperwiki.com/scrapers/stratforscraper/">scraper</a>. I was able to scrape the email subjects, dates, IDs, and text. Then I ran into yet another issue. Where the email addresses in the to and from fields should have been in the HTML, there was a <a href="https://www.cloudflare.com/apps/scrapeshield">CloudFlare ScrapeShield</a> script. The purpose of ScrapeShield is to stop spam bots from collecting email addresses from websites. This is a good thing, but ScrapeShield becomes problematic when it gets in the way of analysis of documents. Is it more important that Stratfor employees get less spam or that people can analyze the WikiLeaks documents? I would generally say the latter since extra spam is a minor inconvenience (and most is caught by spam filters), but Stratfor employees have no say in this, so that complicates the situation.</p>
<p>While not ideal, one solution is for WikiLeaks to give only their media partners access to machine readable data or have some method of requesting it. Not only does WikiLeaks not give media partners access to machine readable data, but they <a href="http://cryptome.org/2012/06/wikileaks-trap.htm">actively ban their partners from scraping the documents</a>. This ban on scraping and running scripts greatly limits the types of analysis their partners can conduct. It may also make it more time consuming to find documents to write about where network and content analysis could reveal interesting sets of emails faster. This restrictive partnership system may be why so few of the GI Files emails have been released so far. </p>
<p>Network analysis is not possible without the to and from fields of the emails. I found a way where it may be possible to get the to and from emails by converting the emails to PDFs and then scraping the PDFs, but this would be extremely difficult. PDF scraping itself is hard, but automatically scraping thousands of slightly different PDFs may not be possible. Thus, I gave up on the network analysis idea.</p>
<p>WikiLeaks is not only failing to make it easy to help with document release and analysis, but they actively impede anyone who wants to help, including their own partners. While WikiLeaks has done some great things for transparency, the organization has some serious problems with secrecy. This secrecy spreads to their releases and perpetuates closed documents behind walls. As the purpose of WikiLeaks is encouraging greater transparency and accountability through release of restricted information, restricting access to that information again defeats the purpose.</p>
<p>WikiLeaks is dying and if it does not change its methods it will die. Regardless of what happens, some of the <a href="http://www.collateralmurder.com/">successes</a> <a href="http://en.wikipedia.org/wiki/Information_published_by_WikiLeaks#Kaupthing_Bank">of WikiLeaks</a> have shown the world the power of leaking and transparency. These successful releases are not the norm. Most of the WikiLeaks releases and those of other transparency initiatives are rendered useless by the issues discussed above and others.</p>
<p>We can do better. I am not sure exactly what will work, but there are a few tasks I think a successful solution to these problems will contain. I have been working on a <a href="http://transparencytoolkit.org">transparency platform</a> that addresses the issues described above and other problems I have noticed with leaking and other transparency initiatives.</p>
<p><strong>Define</strong><br />
When examining any leaked or released information, it helps to define what information the investigative group has and what information it needs. There seem to be two main parts to this defining stage and tools that could help with the process, defining investigative questions and steps to answer those questions.</p>
<p>First, it may be helpful to define the questions the group wants to answer about the information. These questions will likely change throughout the process, but defining some questions upfront can help guide the investigation. A platform that lets people post, edit, and add answers to questions is a simple place to start for investigation of released documents. </p>
<p>Second, the group needs to define how they will answer each question. This could mean determining what information they need, how they will collect that information, and what types of analysis they will conduct with the information. Again, these steps may change throughout the process, but a list of clearly defined steps to answer the investigation’s questions may be a good starting point. Clearly defined steps or tasks are also helpful because they make it clear how supporters can help with the investigation. That clear path to involvement alone would be a huge improvement over WikiLeaks where supporters struggle to figure out how they can help. Simple task management software could allow people to define and allocate these steps to answer each question. It may even be possible to suggest steps based on the wording of the question or steps already entered. Suggestions like this would make it easier for people to figure out how to conduct the investigation.</p>
<p><strong>Collect</strong><br />
Some investigations may start around a particular set of documents the group has already. This often seems to be the case with leaking and whistleblowing. In this case, it may be helpful for these documents to be uploaded in one place so people can search and analyze them. These documents should also be uploaded in a machine readable format for analysis. These two goals can be accomplished with a combination of a searchable document storage/upload system and scrapers. </p>
<p>The group examining the released documents may want to collect related information like interviews, data sets, documents released by other organizations, or user contributed data. Or maybe someone has questions and has no documents to start with yet when finding an answer. These additional documents could also be uploaded to the central storage/upload system to make it easier to search, combine, and analyze all the information. This document collection system could go a step further make it easier to find documents with options to pull information from common data sources like government data APIs, Wikipedia, and search results at the click of a button. Additionally, people helping with the investigation could use a browser plugin to easily send documents or scrape web pages they find online to the information storage system.</p>
<p>Sometimes a whistleblower may want to upload related documents anonymously. An <a href="https://globaleaks.org/">anonymous</a> <a href="http://www.newyorker.com/strongbox/">submission system</a> could be adapted to send documents directly to the storage/upload system. There could also be options for automatic redaction of names (or emails) in the documents submitted by whistleblowers (perhaps with a way some people can access the full data). </p>
<p>After all of this information is uploaded, it would be nice if it could be used outside this single investigation. Thus, it could be helpful to give the person uploading documents the option to share them with others using the same document collection system. This sharing system would make it easy to import documents and data into a new investigation or instance of the information collection and storage system.</p>
<p><strong>Analyze</strong><br />
Collecting and releasing documents only goes so far. To use information, people need to understand it. The analysis used to understand the documents includes anything from reading and discussing the documents to combining different forms of information and using content or network analysis programs. The most helpful type of analysis will vary based on the type of information available and questions asked.</p>
<p>Plenty of analysis tools exist, but a toolkit of many different analysis tools (existing and new) that allows these tools to be easily linked together and use information from the document collection system would make them easier to use and more powerful. For example, users could set one tool to parse a set of data from the document collection system and pass the output of that tool to another that does content analysis to determine relevant Wikipedia pages and then have another tool pull dates from those pages. Another tool could then format the dates and the dates in the original data into the format required by TimelineJS and then have TimelineJS with those dates embedded on the analysis/results page. Each of these tools could be used on their own or with different tools as well. Such an analysis toolkit would make existing tools easier to use and make them more powerful by allowing people to hook them together without coding. People who can code could upload their own tools for others to use or modify existing ones.</p>
<p><strong>Release</strong><br />
While the system described above may help with collecting and analyzing information, it may still be too time consuming and complicated for someone who just wants to learn about a situation and not take part in the investigation. With all the questions, documents, and analysis in one place, a program could easily take all of these and reformat them for a release page. This release page could have summaries and basic information on the findings at the top with the full details from the investigation, analysis, and full documents underneath. While the investigation system would be structured to make it easy to contribute, the release page would be structured to make the information easy to read and understand.</p>
<p>No matter how nice the release system and investigation platform is, few people will find the release pages on their own. People need to write articles about the release and share links to the release page. WikiLeaks’s release model of having media partners write articles is not all bad. I think media partners can be a helpful part of a disclosure system so long as documents are not only released when media partners write articles and they have the tools to help with analysis.</p>
<p><strong>Using the Information</strong><br />
Collecting documents, analyzing them, and releasing more understandable information is not helpful if no one uses the information for anything. Using the released information can take many forms, so I am focusing on the first steps mostly for now. That said, the same structure that helps people define questions and steps to answer them could be used to set specific goals for change or greater awareness based on the released information.</p>
<p><strong>Next Steps</strong><br />
Tools exist to help with all of the steps described above. Some people already use these to examine leaked or released documents. Unfortunately, these tools are often difficult to use and identifying and using many different tools or methods quickly becomes cumbersome, so in many cases they are not used at all. I am building the system I described above. This system integrates both existing tools and new ones in a modular and extensible platform for collaborative investigation. </p>
<p>Hopefully this platform will at least make it easier for organizations already releasing or analyzing leaked and released documents to conduct good analyses. Ideally, this system will be directly integrated with sites releasing documents (both leaking organizations and government transparency initiatives) to provide a platform for collaborative investigation and civic engagement between different groups and individuals.</p>
<p><strong>What I Made So Far</strong><br />
I built a prototype of the <a href="http://transparencytoolkitdemo.herokuapp.com/">collaborative investigation platform for defining questions and steps to answer them</a> (minus the automatic suggestions). This also allows people to upload documents, but it does not yet include anything close to the upload system I described. I also made a few small analysis tools to help analyze the Global Intelligence Files. These tools are a <a href="https://scraperwiki.com/scrapers/stratforscraper/">scraper</a> that can pull all the GI Files, specific releases, and single emails, a <a href="https://github.com/Shidash/TimelineGen%E2%80%9D">gem to automatically generate a TimelineJS-compatible JSON from the scraped emails</a>, and a <a href="http://transparencytoolkitdemo.herokuapp.com/tasks/23">modification of the upload system</a> that embeds a timeline of emails from a single GI Files release when someone uploads the JSON of that release generated by the scraper.</p>
<p>For now, you have to run the scraper <a href="https://scraperwiki.com/scrapers/stratforscraper/">on ScraperWiki</a>, but I hope to integrate it more directly with Transparency Toolkit in the future. The main Transparency Toolkit system can be tested on <a href="http://transparencytoolkitdemo.herokuapp.com/">the demo site</a> (where I’ve uploaded some of the GI Files) or <a href="https://github.com/Shidash/Transparency-Toolkit">downloaded from Github</a>. The TimelineGen gem can be used as a gem or <a href="https://github.com/Shidash/TimelineGen">downloaded from Github</a>. Currently you can only make timelines directly on Transparency Toolkit from specific GI Files release pages, but TimelineGen has methods that can be used in more general cases (I’m still hooking them together manually for the timeline embed). </p>
<p>This is a tutorial/demo video that shows how this works-</p>
<p><iframe width="584" height="329" src="http://www.youtube.com/embed/lBfIMDRc9co?feature=oembed" frameborder="0" allowfullscreen></iframe></p>
<p>If you want to use Transparency Toolkit to make timelines of WikiLeaks GI Files releases, some instructions are below. At this point, it is helpful if you know the basics of how to use ScraperWiki.</p>
<p>1. Go to <a href="https://transparencytoolkitdemo.herokuapp.com/%E2%80%9D">http://transparencytoolkitdemo.herokuapp.com/</a></p>
<p>2. Ask a question or set a goal by typing in the box at the top (or skip this if you want to add a task to an existing question).</p>
<p>3. Click the + button next to the question to which you want to add a task and add a task by typing in the box that says “Add a task”. Tasks are clearly actionable steps for answering the question, like making a timeline of a set of emails.</p>
<p>4. Go to <a href="http://wikileaks.org/gifiles/releases.html">the GI Files release page</a> and click on one of the links to view a set of emails that was released. Copy the URL of the page with the set of emails.</p>
<p>5. Go to <a href="https://scraperwiki.com/scrapers/stratforscraper/edit/">the GI Files scraper</a> and scroll down to line 99 right under ﻿&#8221;#To get all emails for a single gifiles release:”. Then replace the URL in the getEmail(url) method with the URL you copied in step 4.</p>
<p>6. Save and run the scraper.</p>
<p>7. Click “Back to scraper overview” in the top right corner. Then click the Download menu and choose “As a JSON file”. Be sure to clear the old data before running the scraper again.</p>
<p>8. Go back to the task page you created on Transparency Toolkit in step 3. Click the “Contribute results from task” field and type anything you want about the results.</p>
<p>9. Click the Browse button and select the JSON you downloaded in step 7. Submit the results</p>
<p>10. You should see a timeline of the emails on the release page you specified. You can see an example timeline <a href="https://transparencytoolkitdemo.herokuapp.com/tasks/23%E2%80%9C">here</a> as well.</p>
			</div><!-- .entry-content -->

	<footer class="entry-meta">
		This entry was posted in <a href="category/all/index.html" rel="category tag">All</a>, <a href="category/final-projects/index.html" rel="category tag">Final Projects</a> by <a href="author/mc/index.html">MC</a>. Bookmark the <a href="index.html%3Fp=2993.html" title="Permalink to Problems with WikiLeaks and the Start of a Solution" rel="bookmark">permalink</a>.		
			</footer><!-- .entry-meta -->
</article><!-- #post-2993 -->

						<div id="comments">
	
	
	
	
</div><!-- #comments -->

				
			</div><!-- #content -->
		</div><!-- #primary -->


	</div><!-- #main -->

	<footer id="colophon" role="contentinfo">

			

			<div id="site-generator">
												<a href="https://wordpress.org/" class="imprint" title="Semantic Personal Publishing Platform">
					Proudly powered by WordPress				</a>
			</div>
	</footer><!-- #colophon -->
</div><!-- #page -->

<script type='text/javascript' src='wp-includes/js/comment-reply.min.js%3Fver=5.2'></script>
<script type='text/javascript' src='wp-includes/js/wp-embed.min.js%3Fver=5.2'></script>

</body>
</html>
